diff --git a/detect.py b/detect.py
index f2d9f36..b13692f 100644
--- a/detect.py
+++ b/detect.py
@@ -7,6 +7,11 @@ import torch
 import torch.backends.cudnn as cudnn
 from numpy import random
 
+import sys
+import logging
+
+from torch2trt import torch2trt
+
 from models.experimental import attempt_load
 from utils.datasets import LoadStreams, LoadImages
 from utils.general import check_img_size, non_max_suppression, apply_classifier, scale_coords, xyxy2xywh, \
@@ -32,6 +37,18 @@ def detect(save_img=False):
     # Load model
     model = attempt_load(weights, map_location=device)  # load FP32 model
     imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size
+
+    x = torch.ones((1, 3, imgsz, imgsz), device=device)
+    try:
+        model_trt = torch2trt(model, [x], fp16_mode=True)
+    except:
+        logging.exception('could not create tensorRT model')
+        # import pdb
+        # t, v, tb = sys.exc_info()
+        # sys.last_type, sys.last_value, sys.last_traceback = t, v, tb
+        # pdb.pm()
+        exit()
+
     if half:
         model.half()  # to FP16
 
@@ -59,6 +76,7 @@ def detect(save_img=False):
     t0 = time.time()
     img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img
     _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once
+    _ = model_trt(img) if device.type != 'cpu' else None  # run once
     for path, img, im0s, vid_cap in dataset:
         img = torch.from_numpy(img).to(device)
         img = img.half() if half else img.float()  # uint8 to fp16/32
@@ -67,12 +85,17 @@ def detect(save_img=False):
             img = img.unsqueeze(0)
 
         # Inference
+        t_trt = time_synchronized()
+        pred = model_trt(img)[0]
+        print('trt pred (%.3fs)' % (time_synchronized() - t_trt))
+
         t1 = time_synchronized()
         pred = model(img, augment=opt.augment)[0]
+        t2 = time_synchronized()
+        print('torch pred. (%.3fs)' % (t2 - t1))
 
         # Apply NMS
         pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)
-        t2 = time_synchronized()
 
         # Apply Classifier
         if classify:
diff --git a/models/yolo.py b/models/yolo.py
index 256da5d..e4ac6b5 100644
--- a/models/yolo.py
+++ b/models/yolo.py
@@ -90,6 +90,7 @@ class IDetect(nn.Module):
         # x = x.copy()  # for profiling
         z = []  # inference output
         self.training |= self.export
+        print(f'doing training: {self.training}')
         for i in range(self.nl):
             x[i] = self.im[i](self.m[i](self.ia[i](x[i])))  # conv
             bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
